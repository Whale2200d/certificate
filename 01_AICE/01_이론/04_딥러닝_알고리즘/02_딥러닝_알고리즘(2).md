# 학습 목표

- 앞선 노드의 동작원리를 바탕으로, DNN의 학습 방법을 알 수 있다.
- 딥러닝의 가중치를 어떻게 찾아내는지 알 수 있다. 즉, 오차가 적은 예측값을 찾기 위해 어떻게 학습하는지 알 수 있다.

# 학습 방법(1)

인공신경망은 어떻게 예측하는가?

- 예시: x가 2일 때, y가 2610원이라면, w를 어떻게 추론
  1. 임의의 값(1000)을 w에 사용
  2. y는 2000이 나옴
  3. 610만큼 차이(Error) 발생
  4. 임의의 값보다 큰 값을 넣어야 한다는 사실 확인
  5. 새로운 임의의 값(1400)을 w에 사용
  6. y는 2800이 나옴
  7. -190만큼 차이(Error) 발생
  8. 임의의 값보다 작은 값을 넣어야 한다는 사실 확인
  9. 새로운 임의의 값(1305)을 w에 사용
  10. y는 2610이 나옴

- 예시 기반 내용
  1. 예측함수 정의: weight 설정
  2. loss 산출: 예측값 - 실제값
  3. weight 업데이트: loss를 줄이는 방향

  &Rightarrow; 해당 과정을 1회를 iteration이라고 함.

- 가중치 업데이트는 경사하강법(Gradient Descent)
- 경사하강법은 단계적 접근방식을 취하며 조금씩 개선하는 최적화 방법

딥러닝 학습방법

- Node에서 input과 weight를 곱하고 Sum한 뒤 Activation 함수로 특징 값 추출(output)
- Hidden layer는 FC(Fully Connected, Dense Connected)
- Forward Propagation, Error Back Propagation
  - Forward Propagation: 가중치를 설정, 예측값을 뽑는 과정
  - Error Back Propagation: 예측값 토대로 가중치를 전달 업데이트

- 학습방법: 딥러닝 모델의 매개변수(weight, bias)를 무작위로 부여한 후, 반복학습을 통해 모델의 출력값을 정답과 일치하도록 매개변수를 조금씩 조정
- Back Propagation: 실제값과 모델 결과값(예측값)에서 오차를 구해 output에서 input 방향으로 보냄. 가중치를 업데이트하면서 재학습
- Gradient Descent: 뉴럴넷이 가중치 파라미터들을 최적화하는 방법. 손실함수의 현 가중치에서 기울기(Gradient)를 구해서 Loss를 줄이는 방향으로 업데이트 해 나감

# 마무리

1. 딥러닝은 반복학습을 통해 매개변수(Weight, bias)를 학습한다.
2. Weight를 찾기 위한 알고리즘으로 경사하강법을 사용한다.
3. 순전파를 통해 "예측함수를 통해 예측"하고 Loss를 구한다.
4. 역전파를 통해 Weight를 업데이트한다.
