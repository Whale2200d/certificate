# 동작 원리

- 뇌의 정보처리방식을 모사한 "인공신경망"으로 여러 층(Layer)으로 깊이있게(Deep) 구성하여 학습 진행
- Deep Neural Network(DNN)
- 예시:
  1. 자극을 받기
  2. 전달할지 정하기
  3. 전달하기
- Node = 퍼셉트론(자극 전달 받음, 전달 결정, 특징 추출기)
- Layer = input layer, hidden layer, output layer로 구성

퍼셉트론(노드)

- $sum = \sum(x_n w_n)$
- activation는 Step 함수(0을 기준으로 0, 1 판단) 사용
- bias라는 민감도 개념을 추가

## Activation Function

- Binary Step: $f(x) = 0 \, for \, x < 0,\,\,\, 1 \, for \, x \ge 0$
- Logistic, Sigmoid, soft step: $f(x) = \sigma(x) = 1/(1+e^{-x})$
- tanh(Hyperbolic tangent): $f(x) = tanh(x) = (e^x-e^{-x})/(e^x+e^{-x})$
- ReLU(Rectified linear unit): $f(x) = max\(0, x\)$

# 마무리

1. DNN은 인간 뇌의 신경망과 유사하게 만들었다.
2. DNN은 퍼셉트론(노드)로 구성된다.
3. 퍼센트론(노드)는 입력 x Weight를 Sum하고, 활성화함수를 거쳐 전달한다.
4. DNN은 노드의 모음인 Layer를 깊게 쌓아 만든 구조다.
