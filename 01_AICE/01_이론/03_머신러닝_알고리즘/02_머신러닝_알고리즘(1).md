# 머신러닝 기본 개념

- Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks

## 머신러닝의 유형

- 지도학습, 비지도학습

## 지도학습 이해하기

- 10명의 학생의 공부시간으로 시험성적을 예측하는 예제
- 독립변수는 공부시간, 종속변수는 시험성적, 각 행은 관측치
- 종속변수가 존재하기 때문에 지도학습 사용

단순 선형 회귀

- 일차함수와 동일
- 최적의 절편과 기울기는 "오차와 비용 함수"로 찾을 수 있다.

## 오차와 비용 함수

- 오차 = 실제값 - 예측값
- 10명의 학습으로 발견된 10개의 오차가 모두 최소화되는 것이 목표
- 10개의 개별 오차를 이용해 모델 전체의 오차를 줄이는 방향을 고민해야 함.
- 전체 오차의 크기를 대표할 만한 값을 찾아야 함.
  - 평균: 음수가 존재하므로, 상쇄되어 결과 오류 발생
  - 분산: 제곱 또는 절대값으로 상쇄 오류 해결. 단, 절대값의 경우 표준편차를 구할 때 미분이 불가하므로, 제곱 사용
    - 오차의 제곱을 구하고 평균 계산(평균제곱오차, MSE)
    - $MSE = (\sum(n번째 오차)^2) / n(행 개수)$

# 머신러닝 학습방법

- 앞선 예시에서 모델을 학습시킨 게 아니라, 임의로 설정한 B1, B0의 다양한 조합을 이용해서 각각 MSE를 계산했고, 이 중에서 가장 작은 MSE를 가진 모델을 찾았다. 하지만, 이 모델이 최적 모델은 아니다.
- 우리는 학습한 것이 아니라, 몇 가지 조합을 나열해 그 중 가장 좋은 것을 골랐을 뿐이다. 머신러닝은 어떻게 학습하여 최적의 모델을 찾는가?
- 최적의 모델은 MSE(비용함수, 목적함수)가 최소가 되는 모델이다. 우리는 MSE가 최소가 되는 B1, B0를 찾아주는 방법을 찾으면 된다.
  - 경사하강법: $\beta_1$, $\beta_0$가 최소가 되는 **방법을 찾아주는 방법**
    - 예시:
      1. 절편 $\beta_0$가 없다고 가정
      2. $MSE = \sum(시험성적_i - (\beta_1 * 공부시간_i))^2 / 10$
      3. 결과는 $MSE = a*\beta_1^2 + b*\beta_1 + c$인 이차방정식
      4. 이차방정식 그래프에서 목적 함수의 최소값을 구할 수 있다. (접선의 기울기 0)
      5. 같은 방법으로 $\beta_0$까지 사용할 경우, 3차원의 포물선 그래프를 그릴 수 있다.
    - 접선의 기울기를 계산해서 절대값이 작아지는 지점으로 이동하면서 더 나은 $\beta_1$을 찾는다.
    - 학습하는 $\beta_1$의 간격은 어떻게 설정할까?
      - 해당 간격을 학습률(Learning Rate)라고 함.
      - 너무 크면 접선의 기울기가 0인 지점을 지나치고, 너무 작으면 학습 시간이 오래 걸림. 적당한 학습률 설정 필요.
