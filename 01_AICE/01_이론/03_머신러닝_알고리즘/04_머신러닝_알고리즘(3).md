# 머신러닝 대표모델(2)

## 의사 결정 나무

- 의사결정 구조를 나무 형태로 나타냄
- 전체 데이터를 작은 집단으로 나누는 방식이다.
- 독립변수(Feature)를 기준으로 질문하여 데이터를 분류한다.
  - 예시: 독립변수(공부시간, 시각횟수, 흥미 여부)
    1. 공부시간 <= 1.5
    2. 흥미 === YES
    3. 지각횟수 >= 2
- 독립변수를 기준으로 분할되는 부분을 노드
  - 분할되기 전 최초 노드를 **뿌리 노드(Root Node)**
  - 중간에 있는 노드를 **중간 노드(Intermdeidate Node)**
  - 끝에 있는 노드를 **끝 노드(Terminal Node)**
  - 뿌리 노드 ~ 끝 노드까지 층수를 **깊이(Depth)**
    - $깊이 = 중간 노드 개수 + 1$

의사결정 나무는 어떻게 예측하는가?

- 끝 노드의 분류 또는 회귀 결과에 따라 값을 예측
  - 끝 노드의 학생의 **합격 여부 최빈값**이 합격이라면 합격으로 예측
  - 끝 노드의 학생의 **시험 성적 평균값**이 81이라면 81로 예측

의사결정 나무에서 나뉘는 기준점을 어떻게 찾을 수 있나?

- 예시: 공부시간을 어떤 숫자 값으로 분할할까?
- 분류 모델일 경우, 불순도가 낮아지는 조건으로 찾는다.
- 회귀 모델일 경우, MSE가 낮아지는 조건으로 찾는다.

분류 모델 - 불순도

- 분류 모델은 특정 범주로 데이터를 분류하는 것이 목적
- 각 노드를 나누는 기준점을 설정할 때 해당 기준점을 지난 뒤, 불순도가 가장 낮아지는 조건을 고려한다.
- 여러 조건으로 노드를 나누고, 각 조건으로 나눴을 때 불순도가 더 낮아지는 조건을 채택한다.

- 기준이 되는 컬럼이 카테고리라면 기준이 명확하지만, 수치형이라면 아래와 같이 진행한다.
- 예시:
  - 공부시간 기준 불순도 확인
    1. 공부시간 오름차순 정렬
    2. 시험결과가 변하는 지점을 기준으로 앞 뒤 데이터의 평균을 기준점 후보로 설정
    3. 기준점 후보별로 노드 분기 결과 중 가장 불순도가 낮은 경우를 최종 기준점으로 채택

회귀 모델 - MSE

- 회귀 모델은 분기 이후 MSE가 최소가 되는 기준을 찾아간다.
- 카테고리 컬럼의 경우는 수치형 컬럼을 계산하는 방식과 유사
  - 예시: 흥미 여부 기준 MSE 확인
    1. 흥미 여부 오름차순 정렬 (NO &rarr; YES)
    2. NO에서 YES로 바뀌는 지점을 기준으로 그루핑하여 각 그룹의 평균값으로 오차 계산하여 MSE에 사용
- 만약 컬럼이 수치형이라면 동일한 방식으로 MSE를 계산하면 되지만, 중복되는 수치가 없는 만큼 분기 기준이 많아짐.
  - 계산 방법: 지각 횟수 0~5 MSE 확인
    1. 0에서 1로 바뀌는 지점, 1에서 2로 바뀌는 지점 등 총 5개 지점에 대한 평균값 계산
    2. 지각횟수의 평균을 기준으로 작거나 같은 영역, 큰 영역의 각 평균을 구하고, 구한 평균을 이용해 MSE 계산
    3. 각 독립변수에 따른 MSE 값 도출 가능
    4. 이 중에서 가장 작은 MSE 확인
  - 예시: 지각 횟수 0~5 MSE 확인
    1. 예를 들어 첫 번째 지점은 0에서 1로 변하는 지점이므로, 지각횟수의 평균은 0.5($=(0+1)/2$)
    2. 이를 기준으로 0.5보다 작거나 같은 영역의 평균은 84($=(80+88)/2$)
    3. 이를 기준으로 0.5보다 큰 영역의 평균은 60.8($=(76+...+32)/8$)
    4. 0.5보다 작거나 같은 영역은 84로 오차 계산 후 제곱
    5. 0.5보다 큰 영역은 60.8로 오차 계산 후 제곱
    6. $MSE = 개별 제곱의 합산 / 10$
    7. 같은 방법으로 다섯 번째 지점까지 MSE 계산
- 흥미 여부 1개, 지각횟수 5개, 공부시간 9개의 MSE 값을 도출 가능

- 의사결정 나무에서 학습이란, 각 분기 기준을 찾아가는 과정을 의미한다.

## 랜덤 포레스트

- 앞서 학습한 의사결정 나무 모델을 모아서 만든 알고리즘
- 경우에 따라서 다르지만 대체로 좋은 성능 보여주는 것으로 알려져있음
- 랜덤 포레스트를 이해하기 위해선 의사결정 나무를 어떻게 활용했는지 이해해야 한다.
  - 배깅이라는 앙상블 기법을 사용함.
  - 단순하게 집단지성과 유사
  - 다수의 머신러닝 모델을 학습시키고, 각 모델이 예측한 결과를 모은 뒤,
    - 분류라면 투표를 하고 다수결의 원칙에 의해 최종 예측값을 정한다.
    - 회귀라면 예측한 결과의 평균을 최종 예측값으로 사용한다.
- 각 모델이 사용하는 데이터는 전체 데이터에서 중복을 허용한 랜덤 샘플링을 통해 만든다.
  - 학습 데이터가 10개 있다고 가정해보면, 그 중 8개를 골라 각 머신러닝에 학습시키는 방식이다.

- 장점: 단일 의사결정 나무에 비해 성능이 우수
- 단점: 모델이 복잡하므로, 원인 분석이 어려움
  - 여러 개의 나무 모델을 사용하므로, 학습에 소요되는 시간이 늘어남.

# 마무리

- 의사결정 나무는 나무 뿌리와 유사한 구조로 전체 집단을 작은 집단으로 나누는 방식으로 동작, 분기 기준이 명확하게 존재하기 때문에 예측 결과에 대한 **원인 분석하기에 적합**한 알고리즘
- 랜덤 포레스트는 다수의 의사결정 나무를 배깅 기법으로 묶어 만든 알고리즘, 의사결정 나무보다 복잡한만큼 학습 속도는 느리지만 성능은 좋아짐.
